{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4509ab5",
   "metadata": {},
   "source": [
    "<h3>Name: K Lalith Aditya</h3>\n",
    "<h3>Class : 1 MSC</h3>\n",
    "<h3>Regd No: 22231</h3>\n",
    "<h3>Pandas Assignment</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bccfe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4daa7",
   "metadata": {},
   "source": [
    "# 1.Createing Series from numpy array , list, dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "914fd08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    w\n",
      "1    g\n",
      "2    n\n",
      "3    b\n",
      "4    w\n",
      "dtype: object\n",
      "0    w\n",
      "1    g\n",
      "2    n\n",
      "3    b\n",
      "4    w\n",
      "dtype: object\n",
      "0    w\n",
      "1    g\n",
      "2    n\n",
      "3    b\n",
      "4    w\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "mylist = list('wgnbwrgrhgbrhbg') # creating a list \n",
    "myarr  = np.arange(len(mylist))  # creating an array\n",
    "mydict = dict(zip(myarr,mylist)) # creating a dictionary with keys as myarr and values as mylist\n",
    "\n",
    "mySer1 = pd.Series(mylist) # creating Series from list\n",
    "mySer2 = pd.Series(myarr)  # creating Series from array\n",
    "mySer3 = pd.Series(mydict)  # creating Series from dictionary\n",
    "print(mySer3.head())\n",
    "print(mySer3.head())\n",
    "print(mySer3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f44a8ec",
   "metadata": {},
   "source": [
    "# 2.Coverting Series index to a column in a Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3717ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>h</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index   0\n",
       "0     a   0\n",
       "1     b   1\n",
       "2     c  19\n",
       "3     d   7\n",
       "4     e  17\n",
       "5     f  21\n",
       "6     g  18\n",
       "7     h  20\n",
       "8     n  15"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylist = list('sdgbbgwbvgeywvguvwegyv') # creating a list\n",
    "myarr = np.arange(len(mylist))  # creating an array\n",
    "mydict = dict(zip(mylist,myarr)) # creating a dictionary\n",
    "\n",
    "mySeries = pd.Series(mydict)\n",
    "\n",
    "df = mySeries.to_frame().reset_index()  # Series are converted to DataFrame\n",
    "df['index']=['a','b','c','d','e','f','g','h','n']  \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c66907",
   "metadata": {},
   "source": [
    "# 3.How to combine many series to form a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed0f38c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col1  col2\n",
      "0    a     0\n",
      "1    f     1\n",
      "2    u     2\n",
      "3    e     3\n",
      "4    u     4\n",
      "\n",
      "\n",
      "   0  1\n",
      "0  a  0\n",
      "1  f  1\n",
      "2  u  2\n",
      "3  e  3\n",
      "4  u  4\n"
     ]
    }
   ],
   "source": [
    "mylist = list('afueuigbeuigiuebgiuebg') # list\n",
    "myarr = np.arange(len(mylist)) # array\n",
    "\n",
    "ser1 = pd.Series(mylist) # series from list\n",
    "ser2 = pd.Series(myarr) # series from array\n",
    "\n",
    "df = pd.DataFrame({'col1':ser1,'col2':ser2})  # Data Frame with column names as col1 and col2 and values of ser1 and ser2\n",
    "df2 = pd.concat([ser1,ser2],axis=1) # Data Frame where we concat both series \n",
    "\n",
    "print(df.head())\n",
    "print(\"\\n\")\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e75b90",
   "metadata": {},
   "source": [
    "# 4.How to assign name to the seriesâ€™ index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e47454c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     a\n",
      "1     f\n",
      "2     u\n",
      "3     e\n",
      "4     u\n",
      "5     i\n",
      "6     g\n",
      "7     b\n",
      "8     e\n",
      "9     u\n",
      "10    i\n",
      "11    g\n",
      "12    i\n",
      "13    u\n",
      "14    e\n",
      "15    b\n",
      "16    g\n",
      "17    i\n",
      "18    u\n",
      "19    e\n",
      "20    b\n",
      "21    g\n",
      "Name: sairam, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#print(ser1)\n",
    "\n",
    "ser1.name = 'sairam' # assigning a name to the series\n",
    "print(ser1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830ae630",
   "metadata": {},
   "source": [
    "# 5.How to get the items of series A not present in series B?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "914e208a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    i\n",
       "14    i\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser1 = pd.Series(list('asfeubfeubibgeiubgujeb')) # series 1\n",
    "ser2 = pd.Series(list('asfeubfzzzzzzzzzgujeb')) # series 2\n",
    "\n",
    "ser1[~ser1.isin(ser2)] # First taking all values of ser1 present in ser2 and negating then displaying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5590372",
   "metadata": {},
   "source": [
    "# 6.How to get the items not common to both series A and series B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bfe3269a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    i\n",
       "9    z\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser1 = pd.Series(list('asfeubfeubibgeiubgujeb')) # series A\n",
    "ser2 = pd.Series(list('asfeubfzzzzzzzzzgujeb')) # series B\n",
    "\n",
    "union = pd.Series(np.union1d(ser1,ser2)) # taking the union of both series\n",
    "intersect = pd.Series(np.intersect1d(ser1,ser2)) # taking intersection of both series\n",
    "union[~union.isin(intersect)] # first taking union elements in intersection then not considering them in the union which gives items not common to both series A and B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8c4485",
   "metadata": {},
   "source": [
    "# 7.How to get the minimum, 25th percentile, median, 75th, and max of a numeric series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a35fecee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25117263,  7.70986507, 10.92259345, 13.36360403, 18.0949083 ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = np.random.RandomState(100)  \n",
    "\n",
    "ser = pd.Series(state.normal(10,5,25))#(parameters are mean ,sd,size)\n",
    "a = np.percentile(ser, q=[0,25,50,75,100]) # from the series we are taking the 0,25,50,75,100 percentile points into a\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f402b6d",
   "metadata": {},
   "source": [
    "# 8. How to get frequency counts of unique items of a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f7086700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f    13\n",
       "a     6\n",
       "b     3\n",
       "d     2\n",
       "e     2\n",
       "c     2\n",
       "g     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(np.take(list('abcfdefgh'), np.random.randint(8, size=30))) # we are taking a list and random.randint of size =30 \n",
    "ser.value_counts() # we are checking the value counts for the list in the series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161beeea",
   "metadata": {},
   "source": [
    "# 9. How to keep only top 2 most frequent values as it is and replace everything else as â€˜Otherâ€™?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dfc242e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 Freq: 1    6\n",
      "3    2\n",
      "2    2\n",
      "4    2\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         3\n",
       "1     Other\n",
       "2         1\n",
       "3         1\n",
       "4         3\n",
       "5     Other\n",
       "6         1\n",
       "7         1\n",
       "8     Other\n",
       "9     Other\n",
       "10        1\n",
       "11        1\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.RandomState(100) # np.random.RandomState\n",
    "ser = pd.Series(np.random.randint(1, 5, [12])) # creating a series with random values \n",
    "\n",
    "print(\"Top 2 Freq:\", ser.value_counts()) # printng the calue counts for a series\n",
    "ser[~ser.isin(ser.value_counts().index[:2])] = 'Other' # taking the top 2 most frequent values and making everything as 'Others'\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92ac1fd",
   "metadata": {},
   "source": [
    "# 10.How to bin a numeric series to 10 groups of equal size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bc802357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.984780\n",
      "1    0.000258\n",
      "2    0.288723\n",
      "3    0.358809\n",
      "4    0.259464\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    10th\n",
       "1     1st\n",
       "2     5th\n",
       "3     6th\n",
       "4     5th\n",
       "dtype: category\n",
       "Categories (10, object): ['1st' < '2nd' < '3rd' < '4th' ... '7th' < '8th' < '9th' < '10th']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(np.random.random(20)) # random series of size=20\n",
    "print(ser.head())\n",
    "\n",
    "pd.qcut(ser, q=[0, .10, .20, .3, .4, .5, .6, .7, .8, .9, 1], \n",
    "        labels=['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th', '10th']).head() # parameters are the series and q is quantiles and labels for the corresponding quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ba3461",
   "metadata": {},
   "source": [
    "# 11. How to convert a numpy array to a dataframe of given shape? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2b78edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f89c993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4\n",
       "0  2  3  4  5  3\n",
       "1  4  6  5  8  8\n",
       "2  6  4  3  6  5\n",
       "3  6  4  6  4  2\n",
       "4  1  9  6  4  8\n",
       "5  1  9  5  4  3\n",
       "6  1  5  6  7  8"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(np.random.randint(1, 10, 35)) # creating a series starting from values 1 to 10 of 35 in number\n",
    "\n",
    "ans = pd.DataFrame(ser.values.reshape(7,5)) # converting the series into Data frames of 7 rows and 5 columns\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58de48a7",
   "metadata": {},
   "source": [
    "# 12. How to import pandas and check the version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5b364a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.3\n",
      "{\n",
      "  \"system\": {\n",
      "    \"commit\": \"e8093ba372f9adfe79439d90fe74b0b5b6dea9d6\",\n",
      "    \"python\": \"3.9.13.final.0\",\n",
      "    \"python-bits\": 64,\n",
      "    \"OS\": \"Windows\",\n",
      "    \"OS-release\": \"10\",\n",
      "    \"Version\": \"10.0.19044\",\n",
      "    \"machine\": \"AMD64\",\n",
      "    \"processor\": \"Intel64 Family 6 Model 23 Stepping 10, GenuineIntel\",\n",
      "    \"byteorder\": \"little\",\n",
      "    \"LC_ALL\": null,\n",
      "    \"LANG\": null,\n",
      "    \"LOCALE\": {\n",
      "      \"language-code\": \"English_India\",\n",
      "      \"encoding\": \"1252\"\n",
      "    }\n",
      "  },\n",
      "  \"dependencies\": {\n",
      "    \"pandas\": \"1.4.3\",\n",
      "    \"numpy\": \"1.23.1\",\n",
      "    \"pytz\": \"2022.1\",\n",
      "    \"dateutil\": \"2.8.2\",\n",
      "    \"setuptools\": \"58.1.0\",\n",
      "    \"pip\": \"22.0.4\",\n",
      "    \"Cython\": null,\n",
      "    \"pytest\": null,\n",
      "    \"hypothesis\": null,\n",
      "    \"sphinx\": null,\n",
      "    \"blosc\": null,\n",
      "    \"feather\": null,\n",
      "    \"xlsxwriter\": null,\n",
      "    \"lxml.etree\": null,\n",
      "    \"html5lib\": null,\n",
      "    \"pymysql\": null,\n",
      "    \"psycopg2\": null,\n",
      "    \"jinja2\": \"3.1.2\",\n",
      "    \"IPython\": \"8.4.0\",\n",
      "    \"pandas_datareader\": null,\n",
      "    \"bs4\": \"4.11.1\",\n",
      "    \"bottleneck\": null,\n",
      "    \"brotli\": null,\n",
      "    \"fastparquet\": null,\n",
      "    \"fsspec\": null,\n",
      "    \"gcsfs\": null,\n",
      "    \"markupsafe\": \"2.1.1\",\n",
      "    \"matplotlib\": \"3.5.2\",\n",
      "    \"numba\": null,\n",
      "    \"numexpr\": null,\n",
      "    \"odfpy\": null,\n",
      "    \"openpyxl\": null,\n",
      "    \"pandas_gbq\": null,\n",
      "    \"pyarrow\": null,\n",
      "    \"pyreadstat\": null,\n",
      "    \"pyxlsb\": null,\n",
      "    \"s3fs\": null,\n",
      "    \"scipy\": \"1.8.1\",\n",
      "    \"snappy\": null,\n",
      "    \"sqlalchemy\": null,\n",
      "    \"tables\": null,\n",
      "    \"tabulate\": null,\n",
      "    \"xarray\": null,\n",
      "    \"xlrd\": null,\n",
      "    \"xlwt\": null,\n",
      "    \"zstandard\": null\n",
      "  }\n",
      "}None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "print(pd.show_versions(as_json=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f80d4d",
   "metadata": {},
   "source": [
    "# 13. How to extract items at given positions from a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "32907cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     a\n",
       "1     b\n",
       "4     e\n",
       "8     i\n",
       "16    q\n",
       "17    r\n",
       "dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(list('abcdefghijklmnopqrstuvwxyz')) # creating a series\n",
    "pos = [0,1, 4, 8, 16, 17] # list containing positions\n",
    "\n",
    "ans = ser.take(pos) # from the list of positions we are taking correspoding values from the series\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6917558f",
   "metadata": {},
   "source": [
    "# 14.How to stack two series vertically and horizontally ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "477948b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "0    p\n",
      "1    q\n",
      "2    r\n",
      "3    s\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msc 1\\AppData\\Local\\Temp\\ipykernel_16856\\3307822114.py:5: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  a = ser1.append(ser2) # if we do series.append the 2nd series will be made a continuation to series 1 so it becomes a single series\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1\n",
       "0  0    p\n",
       "1  1    q\n",
       "2  2    r\n",
       "3  3    s\n",
       "4  4  NaN"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('pqrs'))\n",
    "\n",
    "# vertically\n",
    "a = ser1.append(ser2) # if we do series.append the 2nd series will be made a continuation to series 1 so it becomes a single series\n",
    "print(a)\n",
    "\n",
    "# horizontally\n",
    "df = pd.concat([ser1,ser2],axis=1) # if we do concat 2 series then it becomes a data frame with each of series as 1 column\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930a9431",
   "metadata": {},
   "source": [
    "# 15.How to get the positions of items of series A in another series B?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "70f94e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 0, 8]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
    "ser2 = pd.Series([1, 3, 10, 13])\n",
    "\n",
    "a=[pd.Index(ser1).get_loc(i) for i in ser2] # all elements are checked with the same elements in series 2 , if it is there then the locations of those elements are taken into the list\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ed4324",
   "metadata": {},
   "source": [
    "# 16.How to compute the mean squared error on a truth and predicted series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eccb0e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3120053848528359"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth = pd.Series(range(10)) # series with values starting from 0 to 10\n",
    "pred = pd.Series(range(10)) + np.random.random(10) # series with values starting from 0 to 10 and some random values are added to corresponding elements in the series\n",
    "\n",
    "ans = np.mean((truth-pred)**2) # we take the meansquare error using numpy\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c02e34",
   "metadata": {},
   "source": [
    "# 17.How to convert the first character of each element in a series to uppercase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "01cedd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     How\n",
       "1      To\n",
       "2    Kick\n",
       "3    Hard\n",
       "dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(['how', 'to', 'kick', 'hard'])\n",
    "\n",
    "pd.Series([i.title() for i in ser]) # We are making each element in the series as Title since Title starts with a capital letter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2f4dec",
   "metadata": {},
   "source": [
    "# 18.How to calculate the number of characters in each word in a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3cb3c097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    2\n",
       "2    4\n",
       "3    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(['how','to','kick','hard']) # creating a series from a list\n",
    "\n",
    "ser.map(lambda x: len(x))  # map module is used to operate with series elements , here we are taking the length of each element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a74722",
   "metadata": {},
   "source": [
    "# 19.How to compute difference of differences between consequtive numbers of a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9f6cdd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 2.0, 3.0, 4.0, 5.0, 6.0, 6.0, 8.0]\n",
      "[nan, nan, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n",
    "\n",
    "print(ser.diff().tolist()) # we are calculating the difference b/w two consecutive numbers of a series\n",
    "print(ser.diff().diff().tolist()) # we are calculating the difference b/w two consecutive numbers of a series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6fdfb8",
   "metadata": {},
   "source": [
    "# 20.How to convert a series of date-strings to a timeseries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "45b146a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-01 00:00:00\n",
       "1   2011-02-02 00:00:00\n",
       "2   2012-03-03 00:00:00\n",
       "3   2013-04-04 00:00:00\n",
       "4   2014-05-05 00:00:00\n",
       "5   2015-06-06 12:20:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "\n",
    "from dateutil.parser import parse # from dateutil.parser module we import parse\n",
    "ser.map(lambda x: parse(x)) # this parse will be used to convert the elements in the series to datetime format\n",
    "\n",
    "pd.to_datetime(ser) # Given strings in the series will be converted to datetime type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9834f222",
   "metadata": {},
   "source": [
    "# 21.How to create a TimeSeries starting â€˜2000-01-01â€™ and 10 weekends (saturdays) after that having random numbers as values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "65f3db4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01    5\n",
       "2000-01-08    9\n",
       "2000-01-15    8\n",
       "2000-01-22    1\n",
       "2000-01-29    1\n",
       "2000-02-05    8\n",
       "2000-02-12    2\n",
       "2000-02-19    8\n",
       "2000-02-26    2\n",
       "2000-03-04    5\n",
       "Freq: W-SAT, dtype: int32"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(np.random.randint(1,10,10), pd.date_range('2000-01-01', periods=10, freq='W-SAT'))\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1539118d",
   "metadata": {},
   "source": [
    "# 22.How to convert year-month string to dates corresponding to the 4th day of the month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2fcb700c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-04\n",
       "1   2011-02-04\n",
       "2   2012-03-04\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012']) # series of values containing month and year\n",
    "\n",
    "from dateutil.parser import parse\n",
    "\n",
    "# parse the date\n",
    "ser_ts = ser.map(lambda x: parse(x)) # parsing the date into date time type\n",
    "\n",
    "# construct date string with date as 4\n",
    "ser_datestr = ser_ts.dt.year.astype('str') + '-' + ser_ts.dt.month.astype('str') + '-' + '04'\n",
    "\n",
    "# by formatting we get\n",
    "[parse(i).strftime('%Y-%m-%d') for i in ser_datestr]\n",
    "\n",
    "ser.map(lambda x: parse('04' + x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a2f679",
   "metadata": {},
   "source": [
    "# 23.How to filter words that contain atleast 2 vowels from a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "89c6b1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Apple\n",
       "1    Orange\n",
       "4     Money\n",
       "dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money']) # creating a series from a list containing fruit names\n",
    "\n",
    "from collections import Counter # Importing Counter from collections module\n",
    "mask = ser.map(lambda x: sum([Counter(x.lower()).get(i,0) for i in list('aeiou')]) >=2) # This Counter will check the items in the Series where the elements contain atleast 2 vowels\n",
    "ser[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb0150e",
   "metadata": {},
   "source": [
    "# 24.How to filter valid emails from a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "687313b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    rameses@egypt.com\n",
       "2            matt@t.co\n",
       "3    narendra@modi.com\n",
       "dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
    "\n",
    "import re #re stands for regular expression\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n",
    "\n",
    "mask = emails.map(lambda x: bool(re.match(pattern,x))) # this will check the series elements in the pattern , if the elements contain Series values in pattern then those will be taken into the mask variable\n",
    "emails[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421f50e4",
   "metadata": {},
   "source": [
    "# 25.How to get the mean of a series grouped by another series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d54263e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apple     7.000000\n",
       "banana    5.500000\n",
       "carrot    5.285714\n",
       "dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10)) # creating a series of 10 values containing apple,banana,carrot\n",
    "weights = pd.Series(np.linspace(1, 10, 10))\n",
    "\n",
    "weights.groupby(fruit).mean() # We group weights series with fruit series and get the mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf25cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa200d5b",
   "metadata": {},
   "source": [
    "# 26.How to compute the euclidean distance between two series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb27f27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.16590212458495"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) # creating a series p\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1]) # creating a series q\n",
    "\n",
    "\n",
    "ans = np.linalg.norm(p-q) # using np.linalg we calculate the norm b/w 2 series\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b57598",
   "metadata": {},
   "source": [
    "# 27.How to find all the local maxima (or peaks) in a numeric series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12ae1ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 7], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3]) # creating a series\n",
    "\n",
    "\n",
    "dd = np.diff(np.sign(np.diff(ser))) #  it is used when we calculate the n-th order discrete difference in the above series\n",
    "peak_locs = np.where(dd == -2)[0] + 1 # if the difference is -2 then take that element into peak_locs variable\n",
    "peak_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f19120a",
   "metadata": {},
   "source": [
    "# 28.How to replace missing spaces in a string with the least frequent character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bd1f9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d    4\n",
      "b    3\n",
      "     3\n",
      "e    3\n",
      "a    2\n",
      "c    1\n",
      "g    1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dbcgdebgabedggade'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_str = 'dbc deb abed gade'  # string\n",
    "\n",
    "ser = pd.Series(list('dbc deb abed gade')) # converting string into list and to series\n",
    "freq = ser.value_counts() # taking frequency of items in the series\n",
    "print(freq)  \n",
    "least_freq = freq.dropna().index[-1] # in places of spaces replace them with items with less frequency\n",
    "\"\".join(ser.replace(' ', least_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba03071",
   "metadata": {},
   "source": [
    "# 29.How to create a dataframe with rows as strides from a given series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaa86b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 2,  3,  4,  5],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 6,  7,  8,  9],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [10, 11, 12, 13]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = pd.Series(range(15)) # series L\n",
    "\n",
    "def gen_strides(a, stride_len=5, window_len=5): \n",
    "    \"\"\"\n",
    "    Args: a : type list\n",
    "          stride_len : type int\n",
    "          window_len : type int\n",
    "    Summary: Its used to create a data frame with rows as strides from a given series      \n",
    "    \"\"\"\n",
    "    n_strides = ((a.size-window_len)//stride_len) + 1 # calculating n_strides\n",
    "    return np.array([a[s:(s+window_len)] for s in np.arange(0, a.size, stride_len)[:n_strides]])\n",
    "\n",
    "gen_strides(L, stride_len=2, window_len=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f94636",
   "metadata": {},
   "source": [
    "# 30. How to import only specified columns from a csv file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0860fc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim  medv\n",
      "0  0.00632  24.0\n",
      "1  0.02731  21.6\n",
      "2  0.02729  34.7\n",
      "3  0.03237  33.4\n",
      "4  0.06905  36.2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', usecols=['crim', 'medv']) # reading a csv file and selecting only 2 of them named(crim and medv) into the data frame\n",
    "print(df.head()) # printing the top 5 rows in the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bf6aee",
   "metadata": {},
   "source": [
    "# 31.How to check if a dataframe has any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b102f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv') # reading a csv file\n",
    "df.isnull().values.any() # checking any values which have null in the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b259d49",
   "metadata": {},
   "source": [
    "# 32.How to count the number of missing values in each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f7f83c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')  # reading the csv file\n",
    "\n",
    "n_missings_each_col = df.apply(lambda x: x.isnull().sum()) # in columns if null values are there we are counting them\n",
    "n_missings_each_col.argmax() # returns the maximum missing value count in the column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55865567",
   "metadata": {},
   "source": [
    "# 33.How to replace missing values of multiple numeric columns with the mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0374c482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Min.Price  Max.Price\n",
      "0  12.900000  18.800000\n",
      "1  29.200000  38.700000\n",
      "2  25.900000  32.300000\n",
      "3  17.118605  44.600000\n",
      "4  17.118605  21.459091\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv') # reading a csv file\n",
    "\n",
    "df_out = df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x: x.fillna(x.mean())) # We are taking the min price and max price columns and whatever missing values are there we are replacing with mean of those columns\n",
    "print(df_out.head()) # printing the first 5 rows of df_out data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f8efd2",
   "metadata": {},
   "source": [
    "# 34.How to filter every nth row in a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0773f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Manufacturer    Model     Type\n",
      "0         Acura  Integra    Small\n",
      "20     Chrysler  LeBaron  Compact\n",
      "40        Honda  Prelude   Sporty\n",
      "60      Mercury   Cougar  Midsize\n",
      "80       Subaru   Loyale    Small\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv') # reading a csv file\n",
    "\n",
    "print(df.iloc[::20, :][['Manufacturer', 'Model', 'Type']]) # printing every row with common difference = 20 , starting from 0th row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb3b18d",
   "metadata": {},
   "source": [
    "# 35.  How to create a primary key index by combining relevant columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55fbaae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv', usecols=[0,1,2,3,5]) # reading csv file and using the mentioned columns only from the file\n",
    "\n",
    "df[['Manufacturer', 'Model', 'Type']] = df[['Manufacturer', 'Model', 'Type']].fillna('missing') # filling missing values in columns Manufacturer, Model and Type\n",
    "df.index = df.Manufacturer + '_' + df.Model + '_' + df.Type # calculating index\n",
    "print(df.index.is_unique) # printing if index value is unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d6e170",
   "metadata": {},
   "source": [
    "# 36.How to get the row number of the nth largest value in a column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c36c7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10,-1), columns=list('abc')) #creating a data frame with 10 rows and 3 columns named('a','b','c')\n",
    "# Solution\n",
    "n = 5\n",
    "df['a'].argsort()[::-1][n] # getting the rowth number for 5th largest value in that ath column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24419238",
   "metadata": {},
   "source": [
    "# 37.How to swap two rows of a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1b26368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4\n",
      "0   0   1   2   3   4\n",
      "1  10  11  12  13  14\n",
      "2   5   6   7   8   9\n",
      "3  15  16  17  18  19\n",
      "4  20  21  22  23  24\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))  # creating a data frame with 5 rows and 5 columns with values from 0 to 25\n",
    "\n",
    "def swap_rows(df, i1, i2):\n",
    "    \"\"\"\n",
    "    Args: df - data frame\n",
    "          i1 - row number that will swap with row i2 , type int\n",
    "          i2 - row number with which row i1 gets swapped, type int\n",
    "    Summary: This function will swap the rows i1,i2 for the given data frame and return the data frame\n",
    "    \"\"\"\n",
    "    a, b = df.iloc[i1, :].copy(), df.iloc[i2, :].copy() # copying the rows of data frame into a,b\n",
    "    df.iloc[i1, :], df.iloc[i2, :] = b, a # swapping the rows of the data-frame\n",
    "    return df # returning the data frame\n",
    "\n",
    "print(swap_rows(df, 1, 2)) # we want to swap rows with index 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94382d9e",
   "metadata": {},
   "source": [
    "# 38. How to reverse the rows of a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76b67e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4\n",
      "4  20  21  22  23  24\n",
      "3  15  16  17  18  19\n",
      "2  10  11  12  13  14\n",
      "1   5   6   7   8   9\n",
      "0   0   1   2   3   4\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5, -1)) # creating a data frame with 5 rows and 5 columns and values from 0 to 25\n",
    "\n",
    "print(df.loc[df.index[::-1], :]) # reversing elements for each row-index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca890e8",
   "metadata": {},
   "source": [
    "# 39.How to compute grouped mean on pandas dataframe and keep the grouped column as another column (not index)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f51ee363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fruit     price\n",
      "0   apple  6.666667\n",
      "1  banana  6.666667\n",
      "2  orange  3.666667\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'rating': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)}) # creating a data-frame with 9 rows and 3 columns \n",
    "# First column has all fruit names , 2nd column has the rating , 3rd has price\n",
    "\n",
    "out = df.groupby('fruit', as_index=False)['price'].mean() #each fruits mean price is calculated into an other data frame named out\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b6670e",
   "metadata": {},
   "source": [
    "# 40.How to get the positions where values of two columns match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c85205a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 2, 7], dtype=int64),)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'fruit1': np.random.choice(['apple', 'orange', 'banana'], 10),\n",
    "                    'fruit2': np.random.choice(['apple', 'orange', 'banana'], 10)})\n",
    "\n",
    "# data frame with 2 columns named fruit 1 and fruit 2 with 3 fruit names \n",
    "\n",
    "a=np.where(df.fruit1 == df.fruit2) # where fruit 1 name and fruit 2 name are same in both columns at particular row take the row index into array and print it\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9c6626",
   "metadata": {},
   "source": [
    "# 41.How to create lags and leads of a column in a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "03d1047d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c   d  a_lag1  b_lead1\n",
      "0  49  92  81  19     NaN     11.0\n",
      "1  69  11  24  80    49.0      1.0\n",
      "2  20   1  41  47    69.0     94.0\n",
      "3  70  94  76  43    20.0     57.0\n",
      "4  40  57  55  74    70.0      NaN\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 100, 20).reshape(-1, 4), columns = list('abcd')) # creating a data frame with 5 rows and 4 columns with column names a,b,c,d\n",
    "\n",
    "df['a_lag1'] = df['a'].shift(1) #creating lags from column a\n",
    "df['b_lead1'] = df['b'].shift(-1) #creating leads from column b\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f8fa8a",
   "metadata": {},
   "source": [
    "# 42.How to get the frequency of unique values in the entire dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c7b4acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    5\n",
       "8    4\n",
       "3    3\n",
       "7    3\n",
       "5    2\n",
       "9    1\n",
       "4    1\n",
       "2    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 10, 20).reshape(-1, 4), columns = list('abcd')) # creating 5 rows and 4 columns with column names a,b,c,d and values are from 1 to 10\n",
    "\n",
    "pd.value_counts(df.values.ravel()) # counting the frequency of the unique values int the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f6fe56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b5c4b",
   "metadata": {},
   "source": [
    "# 43.How to find and cap outliers from a series or dataframe column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aecebe00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 %ile:  0.016049294076965887 | 0.95 %ile:  63.87667222018393\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.logspace(-2, 2, 30))  # creating a series with start =-2 and stop=2 , space =30 \n",
    "\n",
    "def cap_outliers(ser, low_perc, high_perc):\n",
    "    \"\"\"\n",
    "    Args: ser - series ,type- Series\n",
    "          low_perc - low percentile, type - float\n",
    "          high_perc - high percentile, type - float\n",
    "    Summary:\n",
    "            It will take outliers from the given series\n",
    "    \"\"\"\n",
    "    low, high = ser.quantile([low_perc, high_perc]) # taking quantiles in the series into low and high\n",
    "    print(low_perc, '%ile: ', low, '|', high_perc, '%ile: ', high) # printing the values\n",
    "    ser[ser < low] = low # series values less than low are equated to low\n",
    "    ser[ser > high] = high  # series values greater than high are equated to high\n",
    "    return(ser) # return series\n",
    "\n",
    "capped_ser = cap_outliers(ser, .05, .95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43765f76",
   "metadata": {},
   "source": [
    "# 44.How to reshape a dataframe to the largest possible square after removing the negative values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ae73c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5   6   7   8   9\n",
      "0  48   2  12  44  23 -13  18 -17  18   0\n",
      "1  18 -20  15  -4  45 -12  -7   5   7  -3\n",
      "2   8  46 -19  33   8  -6  20  34  47  25\n",
      "3  19  -5  34   2  -6  46  41  39 -16   7\n",
      "4  36  43  11  22   1  24   2  26  26  -6\n",
      "5  31  21  21 -14   7  14  -9  40  17  34\n",
      "6 -17  49  44  43  28  21  42  45 -11  31\n",
      "7  12  -4  14  17  39  -6  49  -3  30 -14\n",
      "8  11  25  17  28  43  23  11 -17  43 -20\n",
      "9  46   9 -16   8  18  21   3 -16   0  30\n",
      "[[48. 12. 44. 23. 18. 18. 18. 15.]\n",
      " [45.  8. 46. 33.  8. 20. 34. 47.]\n",
      " [25. 19. 34. 46. 41. 39. 36. 43.]\n",
      " [11. 22. 24. 26. 26. 31. 21. 21.]\n",
      " [14. 40. 17. 34. 49. 44. 43. 28.]\n",
      " [21. 42. 45. 31. 12. 14. 17. 39.]\n",
      " [49. 30. 11. 25. 17. 28. 43. 23.]\n",
      " [11. 43. 46.  9.  8. 18. 21. 30.]]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(-20, 50, 100).reshape(10,-1)) # creating a data frame with 10 rows and 10 columns with values from -20 to 50 and 100 values\n",
    "print(df)\n",
    "\n",
    "# Solution\n",
    "# Step 1: remove negative values from arr\n",
    "arr = df[df > 0].values.flatten()  # converting data frame into a list\n",
    "arr_qualified = arr[~np.isnan(arr)] # what are  not a number in the list remove them and take the rest\n",
    "\n",
    "# Step 2: find side-length of largest possible square\n",
    "n = int(np.floor(arr_qualified.shape[0]**.5))   \n",
    "\n",
    "# Step 3: Take top n^2 items without changing positions\n",
    "top_indexes = np.argsort(arr_qualified)[::-1]  \n",
    "output = np.take(arr_qualified, sorted(top_indexes[:n**2])).reshape(n, -1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5916c34b",
   "metadata": {},
   "source": [
    "# 45.How to create one-hot encodings of a categorical variable (dummy variables)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0614658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  5  10  15  20   b   c   d   e\n",
      "0  1  0   0   0   0   1   2   3   4\n",
      "1  0  1   0   0   0   6   7   8   9\n",
      "2  0  0   1   0   0  11  12  13  14\n",
      "3  0  0   0   1   0  16  17  18  19\n",
      "4  0  0   0   0   1  21  22  23  24\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5,-1), columns=list('abcde')) # creating a data frame with 5 rows and 5 columns(a,b,c,d,e) and values are from 0 to 24\n",
    "\n",
    "df_onehot = pd.concat([pd.get_dummies(df['a']), df[list('bcde')]], axis=1) \n",
    "# We are creating dummy variables for column 'a' where values are nominal and concatenating the remaining b,c,d,e columns with that dummy columns\n",
    "print(df_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e35866f",
   "metadata": {},
   "source": [
    "# 46.Which column contains the highest number of row-wise maximum values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02432103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column with highest row maxes:  3\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1)) #Creating a data frame with 10 rows and 4 columns with random values from 1 to 100\n",
    "\n",
    "\n",
    "print('Column with highest row maxes: ', df.apply(np.argmax, axis=1).value_counts().index[0]) #printing the column which contains highest row-wise maximum values  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5ba8b4",
   "metadata": {},
   "source": [
    "# 47.How to know the maximum possible correlation value of each column against other columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac53b558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Correlation possible for each column:  [0.46 0.68 0.66 0.66 0.5  0.68 0.53 0.53 0.63 0.37]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1), columns=list('pqrstuvwxy'), index=list('abcdefgh'))\n",
    "#data frame with random values 1 to 100 and column names (p,q,r,s,t,u,v,w,x,y) and index values (a,b,c,d,e,f,g,h)\n",
    "\n",
    "abs_corrmat = np.abs(df.corr()) # correlation matrix among columns which contains absolute values \n",
    "max_corr = abs_corrmat.apply(lambda x: sorted(x)[-2]) # calculating the max correlation for each column into list max_corr\n",
    "print('Maximum Correlation possible for each column: ', np.round(max_corr.tolist(), 2)) #printing the max correlation with rounding to 2 decimal values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d60b0d",
   "metadata": {},
   "source": [
    "# 48.How to create a column containing the minimum by maximum of each row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0dcefc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.071429\n",
      "1    0.080460\n",
      "2    0.103896\n",
      "3    0.077778\n",
      "4    0.117647\n",
      "5    0.173913\n",
      "6    0.206897\n",
      "7    0.232323\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1)) # dataframe with 8 rows and 10 columns with random values from 1 to 100\n",
    "\n",
    "min_by_max = df.apply(lambda x: np.min(x)/np.max(x), axis=1) # creating a column containing the minimum by maximum of each row\n",
    "print(min_by_max) # printing the column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfcd6d6",
   "metadata": {},
   "source": [
    "# 49.How to create a column that contains the penultimate value in each row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6481c643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5   6   7   8   9  penultimate\n",
      "0  47   5  31  48  61  80  43  85  79  21           80\n",
      "1  97   1  68  54  97  52   5  57   9  60           68\n",
      "2  49  25  60  19  62  22  59  19  60  90           62\n",
      "3  20   6  43  21  71  43  29  10  91  42           71\n",
      "4  97  75  53   9  21  17  97  78  45  20           78\n",
      "5  32   3  39  24  64  96  15  35  91  81           91\n",
      "6  16  26  49  24  80   8  71  28  74  29           74\n",
      "7  11  97  35  86  57  45  97  19  58  38           86\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1)) # data frame with 8 rows and 10 columns and random values from 1 to 100\n",
    "\n",
    "out = df.apply(lambda x: x.sort_values().unique()[-2], axis=1) #sorting and taking the penultimate value (2nd maximum value) from each row into the variable out \n",
    "df['penultimate'] = out #creating a column with name = penultimate and assigning values of out to that column into dataframe df\n",
    "print(df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a0be4d",
   "metadata": {},
   "source": [
    "# 50.How to normalize all columns in a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32071583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution Q1\n",
      "       0     1     2     3     4     5     6     7     8     9\n",
      "0 -0.62 -0.56  0.25 -1.10  0.01  0.15 -1.23 -0.85  1.03  1.20\n",
      "1 -0.76  1.17  1.24  0.98 -0.22 -1.77 -0.17  1.62 -0.16  1.20\n",
      "2  0.55  1.44 -0.37  0.36  1.27  0.56 -0.81  1.03  0.01  0.14\n",
      "3  1.21  0.67 -1.20 -0.70  0.75  1.47  0.89 -0.48  1.35 -0.37\n",
      "4  1.21 -1.47 -0.73 -0.42  0.70 -1.06  0.57 -0.60  0.88 -0.66\n",
      "5 -0.90 -0.29 -0.84 -1.29 -0.51  0.15  0.99  0.85 -1.24 -1.31\n",
      "6 -1.28 -0.24  0.05  1.10  0.01  0.05  1.03 -0.60 -1.12  0.85\n",
      "7  0.60 -0.70  1.60  1.07 -2.00  0.46 -1.28 -0.97 -0.74 -1.05\n",
      "\n",
      "Solution Q2\n",
      "       0     1     2     3     4     5     6     7     8     9\n",
      "0  0.74  0.69  0.48  0.92  0.39  0.41  0.98  0.95  0.12  0.00\n",
      "1  0.79  0.09  0.13  0.05  0.46  1.00  0.52  0.00  0.58  0.00\n",
      "2  0.26  0.00  0.70  0.31  0.00  0.28  0.80  0.23  0.52  0.42\n",
      "3  0.00  0.27  1.00  0.75  0.16  0.00  0.06  0.81  0.00  0.62\n",
      "4  0.00  1.00  0.83  0.64  0.18  0.78  0.20  0.86  0.18  0.74\n",
      "5  0.85  0.59  0.87  1.00  0.54  0.41  0.02  0.30  1.00  1.00\n",
      "6  1.00  0.58  0.56  0.00  0.39  0.44  0.00  0.86  0.96  0.14\n",
      "7  0.25  0.73  0.00  0.01  1.00  0.31  1.00  1.00  0.81  0.89\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1)) #creating a dataframe with 8 rows and 10 columns with random values 1 to 100\n",
    "\n",
    "out1 = df.apply(lambda x: ((x - x.mean())/x.std()).round(2)) # Normalizing all columns of df by subtracting the column mean and divide by standard deviation. \n",
    "print('Solution Q1\\n',out1) # printing Q1 values\n",
    "print()\n",
    "out2 = df.apply(lambda x: ((x.max() - x)/(x.max() - x.min())).round(2)) # Taking range all columns of df such that the minimum value in each column is 0 and max is 1.\n",
    "print('Solution Q2\\n', out2)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
